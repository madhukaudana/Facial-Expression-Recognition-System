{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display some images for every different expression\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# size of the image: 48*48 pixels\n",
    "pic_size = 48\n",
    "\n",
    "# input path for the images\n",
    "base_path = \"H:/sample_images/images/\"\n",
    "\n",
    "plt.figure(0, figsize=(12,20))\n",
    "cpt = 0\n",
    "\n",
    "for expression in os.listdir(base_path + \"train/\"):\n",
    "    for i in range(1,6):\n",
    "        cpt = cpt + 1\n",
    "        plt.subplot(7,5,cpt)\n",
    "        img = load_img(base_path + \"train/\" + expression + \"/\" +os.listdir(base_path + \"train/\" + expression)[i], target_size=(pic_size, pic_size))\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for expression in os.listdir(base_path + \"train\"):\n",
    "    print(str(len(os.listdir(base_path + \"train/\" + expression))) + \" \" + expression + \" images\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86912b6d63122274"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# number of images to feed into the NN for every batch\n",
    "batch_size = 128\n",
    "\n",
    "datagen_train = ImageDataGenerator()\n",
    "datagen_validation = ImageDataGenerator()\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(base_path + \"train\",\n",
    "                                                    target_size=(pic_size,pic_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_generator = datagen_validation.flow_from_directory(base_path + \"validation\",\n",
    "                                                    target_size=(pic_size,pic_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1c964baf8272eb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# number of possible label values\n",
    "nb_classes = 7\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# 1 - Convolution\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdef9d39e7ea0c59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# Save the model in the recommended Keras format\n",
    "model.save(\"my_model.keras\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35d7e2fe6ddd1080"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your saved model\n",
    "from keras.models import load_model\n",
    "loaded_model = load_model(\"my_model.keras\")\n",
    "\n",
    "# Generate predictions on the validation set\n",
    "validation_generator.reset()\n",
    "predictions = loaded_model.predict(validation_generator, steps=len(validation_generator), verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "print(\"Accuracy:\", accuracy_score(true_classes, predicted_classes))\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
    "\n",
    "# Generate and print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4ca0dbf45cf07a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load the dataset\n",
    "def load_images_from_folder(folder): \n",
    "    for expression in os.listdir(folder):\n",
    "        for filename in os.listdir(os.path.join(folder, expression)):\n",
    "            img = load_img(os.path.join(folder, expression, filename), target_size=(pic_size, pic_size), color_mode=\"grayscale\")\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array.flatten())  # Flatten the image\n",
    "            labels.append(expression)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "train_images, train_labels = load_images_from_folder(os.path.join(base_path, \"train\"))\n",
    "validation_images, validation_labels = load_images_from_folder(os.path.join(base_path, \"validation\"))\n",
    "\n",
    "# Flatten and normalize the image data\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "train_images_scaled = scaler.fit_transform(train_images)\n",
    "validation_images_scaled = scaler.transform(validation_images)\n",
    "\n",
    "# Initialize and train the decision tree classifier\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(train_images_scaled, train_labels)\n",
    "\n",
    "# Predict on validation set\n",
    "predicted_labels = tree_classifier.predict(validation_images_scaled)\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "report = classification_report(validation_labels, predicted_labels, target_names=os.listdir(os.path.join(base_path, \"train\")))\n",
    "conf_matrix = confusion_matrix(validation_labels, predicted_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(validation_labels, predicted_labels))\n",
    "print(report)\n",
    "print(conf_matrix)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5887dc8b996112c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load images and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each expression folder\n",
    "for expression in os.listdir(base_path + \"train/\"):\n",
    "    for img_path in os.listdir(base_path + \"train/\" + expression):\n",
    "        img = Image.open(os.path.join(base_path, \"train\", expression, img_path)).convert('L')  # Open image in grayscale\n",
    "        img = img.resize((pic_size, pic_size))  # Resize image to desired size\n",
    "        img_array = np.array(img)  # Convert image to numpy array\n",
    "        data.append(img_array)\n",
    "        labels.append(expression)\n",
    "\n",
    "# Convert data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "data = data / 255.0\n",
    "\n",
    "# Encode labels to one-hot vectors\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels_one_hot = label_binarizer.fit_transform(labels)\n",
    "\n",
    "# Splitting the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Deep Belief Network model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(X_train.shape[1:])))\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "\n",
    "# Output layer for multi-class classification\n",
    "num_classes = len(np.unique(labels))  # Assuming labels contain class information\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_val, y_val), verbose=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "279c4717033f36c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict on validation data\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Reshape y_pred to match the shape of y_val\n",
    "num_classes = len(np.unique(labels))  # Assuming labels contain class information\n",
    "y_pred_reshaped = np.reshape(y_pred, (-1, num_classes))\n",
    "\n",
    "# Convert predicted and true labels back from one-hot encoding\n",
    "y_true_labels = np.argmax(y_val, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred_reshaped, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Calculate classification report\n",
    "# report = classification_report(y_true_labels, y_pred_labels, target_names=label_binarizer.classes_)\n",
    "report = classification_report(y_true_labels, y_pred_labels, target_names=label_binarizer.classes_, zero_division=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5079e6acd164f17c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images_and_labels(base_path):\n",
    "    for expression in os.listdir(base_path + \"train/\"):\n",
    "        for img_name in os.listdir(base_path + \"train/\" + expression):\n",
    "            img = image.load_img(base_path + \"train/\" + expression + \"/\" + img_name, target_size=(pic_size, pic_size), color_mode=\"grayscale\")\n",
    "            img_array = image.img_to_array(img)\n",
    "            images.append(img_array.flatten())\n",
    "            labels.append(expression)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load images and labels\n",
    "X, y = load_images_and_labels(base_path)\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ae71dc423dc8c19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show the confusion matrix of our predictions\n",
    "\n",
    "# compute predictions\n",
    "predictions = model.predict(validation_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_test = validation_generator.classes\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "# compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb811e827caacacf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
